{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "from torchvision import transforms as TF\n",
    "import torch.nn.functional as F\n",
    "from transformers import get_scheduler\n",
    "from torchvision import transforms\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "from transformers import get_scheduler\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='training_log.log',  # Log dosyas覺n覺n ad覺\n",
    "    filemode='a',                 # Dosya yazma modu (append)\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Log format覺\n",
    "    level=logging.INFO            # Loglama seviyesi\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Custom transform to invert colors for masks\n",
    "class InvertMaskColors(object):\n",
    "    def __call__(self, mask):\n",
    "        if mask.mode != 'L':\n",
    "            raise ValueError(\"Input mask should be in grayscale (L) mode\")\n",
    "        mask = TF.to_tensor(mask)\n",
    "        mask = 1.0 - mask\n",
    "        return TF.to_pil_image(mask)\n",
    "\n",
    "# Custom dataset class\n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, image_transform=None, mask_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_transform = image_transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.images = [img for img in os.listdir(img_dir) if img.endswith(('.jpg', '.png'))]\n",
    "        self.masks = [mask for mask in os.listdir(mask_dir) if mask.endswith(('.jpg', '.png'))]\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        image_basename = os.path.basename(image_path).split('.')[0]\n",
    "        mask_path = os.path.join(self.mask_dir, image_basename + '.png')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        \n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "        \n",
    "        # Convert mask to binary format with 0 and 1 values\n",
    "        mask = TF.to_tensor(mask)\n",
    "        mask = (mask > 0).long()  # Threshold back to binary and convert to LongTensor\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Mean IoU calculation function\n",
    "def mean_iou(preds, labels, num_classes):\n",
    "    preds_flat = preds.view(-1)\n",
    "    labels_flat = labels.view(-1)\n",
    "\n",
    "    if preds_flat.shape[0] != labels_flat.shape[0]:\n",
    "        raise ValueError(f\"Predictions and labels have mismatched shapes: \"\n",
    "                         f\"{preds_flat.shape} vs {labels_flat.shape}\")\n",
    "\n",
    "    iou = jaccard_score(labels_flat.cpu().numpy(), preds_flat.cpu().numpy(),\n",
    "                        average=None, labels=range(num_classes))\n",
    "\n",
    "    return np.mean(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the appropriate transformations\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((360, 640)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((360, 640), interpolation=Image.NEAREST),\n",
    "    InvertMaskColors(),  # Apply InvertMaskColors transform to masks\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "root_dir = \"/home/dlcompute/Yasin/lane-detection\"\n",
    "# Paths to the datasets\n",
    "train_images_dataset_path = f\"{root_dir}/datasets/bdd100k/images/100k/train\"\n",
    "train_masks_dataset_path = f\"{root_dir}/datasets/bdd100k/labels/lane/masks/train\"\n",
    "val_images_dataset_path = f\"{root_dir}/datasets/bdd100k/images/100k/val\"\n",
    "val_masks_dataset_path = f\"{root_dir}/datasets/bdd100k/labels/lane/masks/val\"\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = BaseDataset(img_dir=train_images_dataset_path,\n",
    "                            mask_dir=train_masks_dataset_path,\n",
    "                            image_transform=image_transform,\n",
    "                            mask_transform=mask_transform)\n",
    "\n",
    "valid_dataset = BaseDataset(img_dir=val_images_dataset_path,\n",
    "                            mask_dir=val_masks_dataset_path,\n",
    "                            image_transform=image_transform,\n",
    "                            mask_transform=mask_transform)\n",
    "\n",
    "# Create the data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=6, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'transformlar: {image_transform}, {mask_transform}')\n",
    "logging.info(f'length of dataset train: {len(train_dataset)}, val: {len(valid_dataset)}')\n",
    "logging.info(f'batch size: {batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to visualize a sample\n",
    "def show_sample(dataset, idx):\n",
    "    image, mask = dataset[idx]\n",
    "    images = [img for img in os.listdir(train_images_dataset_path) if img.endswith(('.jpg', '.png'))]\n",
    "    image_pil = Image.open(os.path.join(train_images_dataset_path, images[idx]))\n",
    "    \n",
    "    # Reverse the normalization on image\n",
    "    \n",
    "    # Convert mask tensor to uint8 and then to PIL image for visualization\n",
    "    mask = mask.byte()  # Convert to uint8\n",
    "    mask_pil = TF.to_pil_image(mask)\n",
    "\n",
    "    # Display the images\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(image_pil)\n",
    "    axes[0].set_title('Image')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(mask_pil, cmap='gray')\n",
    "    axes[1].set_title('Mask')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Load a sample from the train dataset\n",
    "show_sample(train_dataset, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name= \"fine_tuned_best_model\"\n",
    "if os.path.exists(save_name):\n",
    "    model_name = save_name\n",
    "else:\n",
    "    model_name = \"nvidia/segformer-b2-finetuned-ade-512-512\"\n",
    "\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(model_name)\n",
    "model.config.num_labels = 2  # Replace with the actual number of classes\n",
    "\n",
    "if model_name == \"nvidia/segformer-b2-finetuned-ade-512-512\":\n",
    "    if os.path.exists(\"best_model.pth\"):\n",
    "        model.load_state_dict(torch.load(\"./best_model.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for CUDA acceleration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "num_epochs = 30\n",
    "\n",
    "num_epochs = 30\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "num_warmup_steps = int(0.1 * num_training_steps)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'num_epochs: {num_epochs}, num_training_steps: {num_training_steps}')\n",
    "logging.info(f'optimizer: {optimizer}, lr_scheduler: {lr_scheduler}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for best mean IoU and best model weights\n",
    "best_iou = 0.0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_iterator = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", unit=\"batch\")\n",
    "    for batch in train_iterator:\n",
    "        images, masks = batch\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).long()  # Ensure masks are LongTensors\n",
    "\n",
    "        # Remove the channel dimension from the masks tensor\n",
    "        masks = masks.squeeze(1)  # This changes the shape from [batch, 1, H, W] to [batch, H, W]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass pixel_values and labels to the model\n",
    "        outputs = model(pixel_values=images, labels=masks,return_dict=True)\n",
    "        \n",
    "        loss = outputs[\"loss\"]\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        outputs = F.interpolate(outputs[\"logits\"], size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "        \n",
    "        train_iterator.set_postfix(loss=loss.item())\n",
    "    logging.info(f'epoch: {epoch} train loss: {loss.item()}')\n",
    "    # Evaluation loop for each epoch\n",
    "    model.eval()\n",
    "    total_iou = 0\n",
    "    num_batches = 0\n",
    "    valid_iterator = tqdm(valid_loader, desc=\"Validation\", unit=\"batch\")\n",
    "    for batch in valid_iterator:\n",
    "        images, masks = batch\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device).long()\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            # Get the logits from the model and apply argmax to get the predictions\n",
    "            outputs = model(pixel_values=images,return_dict=True)\n",
    "            outputs = F.interpolate(outputs[\"logits\"], size=masks.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            preds = torch.unsqueeze(preds, dim=1)\n",
    "\n",
    "        preds = preds.view(-1)\n",
    "        masks = masks.view(-1)\n",
    "    \n",
    "        # Compute IoU\n",
    "        iou = mean_iou(preds, masks, model.config.num_labels)\n",
    "        total_iou += iou\n",
    "        num_batches += 1\n",
    "        valid_iterator.set_postfix(mean_iou=iou)\n",
    "    \n",
    "    epoch_iou = total_iou / num_batches\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Mean IoU: {epoch_iou:.4f}\")\n",
    "    logging.info(f\"Epoch {epoch+1}/{num_epochs} - Mean IoU: {epoch_iou:.4f}\")\n",
    "\n",
    "    # Check for improvement\n",
    "    if epoch_iou > best_iou:\n",
    "        print(f\"Validation IoU improved from {best_iou:.4f} to {epoch_iou:.4f}\")\n",
    "        logging.info(f\"Validation IoU improved from {best_iou:.4f} to {epoch_iou:.4f}\")\n",
    "        best_iou = epoch_iou\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_model_wts, 'best_model.pth')\n",
    "        model.save_pretrained(save_name)\n",
    "        \n",
    "\n",
    "# After all epochs, load the best model weights - optional\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "print(\"Loaded the best model weights!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplr_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
